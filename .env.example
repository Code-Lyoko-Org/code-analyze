# ============================================================
# Code Analyze - 环境变量配置
# ============================================================

# ------------------------------------------------------------
# LLM Configuration (Large Language Model)
# 支持 OpenAI 兼容接口：OpenAI, OpenRouter, Azure, 本地部署等
# ------------------------------------------------------------
LLM_API_URL=https://openrouter.ai/api
LLM_API_KEY=sk-or-your-api-key-here
LLM_MODEL=openai/gpt-4o-mini

# ------------------------------------------------------------
# Embedding Configuration (向量嵌入模型)
# 用于代码语义检索，支持 OpenAI、SiliconFlow 等
# EMBEDDING_DIMENSION 必须与模型输出维度一致
# ------------------------------------------------------------
EMBEDDING_API_URL=https://api.siliconflow.cn
EMBEDDING_API_KEY=sk-your-embedding-key-here
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
EMBEDDING_DIMENSION=1024

# ------------------------------------------------------------
# Langfuse Configuration (可选 - LLM 可观测性)
# 用于追踪 LLM 调用、Token 统计、性能监控
# 注册地址: https://cloud.langfuse.com
# ------------------------------------------------------------
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_HOST=https://cloud.langfuse.com

# ------------------------------------------------------------
# Qdrant Configuration (向量数据库)
# 用于存储和检索代码嵌入向量
# Docker Compose 部署时会自动启动
# ------------------------------------------------------------
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=code_blocks

# ------------------------------------------------------------
# Redis Configuration (缓存)
# 用于缓存分析结果，避免重复计算
# Docker Compose 部署时会自动启动
# ------------------------------------------------------------
REDIS_URL=redis://localhost:6379/0

# ------------------------------------------------------------
# App Configuration (应用配置)
# ------------------------------------------------------------
DEBUG=false
TEMP_DIR=/tmp/code-analyze
