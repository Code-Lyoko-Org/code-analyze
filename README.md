# Code Analyze - AI-Powered Code Review Agent

<div align="center">

**åŸºäº RAG å’Œ LLM çš„æ™ºèƒ½ä»£ç åˆ†æç³»ç»Ÿï¼Œå®ç°ä»éœ€æ±‚åˆ°åŠŸèƒ½å®šä½çš„è‡ªåŠ¨åŒ–éªŒè¯**

[![Python 3.11](https://img.shields.io/badge/Python-3.11-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docker.com)

</div>

---

## ğŸ¯ é¡¹ç›®äº®ç‚¹

| æŠ€æœ¯ç‰¹æ€§ | å®ç°æ–¹æ¡ˆ | è§£å†³çš„é—®é¢˜ |
|---------|---------|-----------|
| **RAG è¯­ä¹‰æ£€ç´¢** | Qdrant å‘é‡æ•°æ®åº“ + Embedding | ç²¾å‡†å®šä½ç›¸å…³ä»£ç ç‰‡æ®µ |
| **Tree-sitter è§£æ** | å¤šè¯­è¨€ AST æŠ½è±¡è¯­æ³•æ ‘ | ç»“æ„åŒ–ä»£ç ç†è§£ï¼Œéæ­£åˆ™åŒ¹é… |
| **å¼‚æ­¥å¹¶è¡Œå¤„ç†** | asyncio.gather æ‰¹é‡åˆ†æ | å¤šç‰¹æ€§å¹¶å‘åˆ†æï¼Œæ˜¾è‘—æé€Ÿ |
| **ReAct è‡ªä¿®å¤å¾ªç¯** | LLM ç”Ÿæˆ â†’ æ‰§è¡Œ â†’ è¯Šæ–­ â†’ ä¿®å¤ | æµ‹è¯•å¤±è´¥è‡ªåŠ¨ä¿®å¤ï¼Œæå‡æˆåŠŸç‡ |
| **Docker-in-Docker** | éš”ç¦»æ²™ç®±æµ‹è¯•ç¯å¢ƒ | å®‰å…¨æ‰§è¡Œç”¨æˆ·ä»£ç ï¼Œæ— æ±¡æŸ“ä¸»æœº |
| **æ™ºèƒ½ç¼“å­˜ç­–ç•¥** | Redis + å†…å®¹å“ˆå¸Œ | é‡å¤è¯·æ±‚ç§’çº§å“åº” |

---

## ï¿½ Part 1: Docker Compose éƒ¨ç½²

### 1.1 ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repo-url>
cd code-analyze

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# å¿…å¡«ï¼šLLM API é…ç½®ï¼ˆæ”¯æŒ OpenAI å…¼å®¹æ¥å£ï¼‰
LLM_API_URL=https://openrouter.ai/api/v1
LLM_API_KEY=sk-or-your-api-key
LLM_MODEL=openai/gpt-4o-mini

# å¯é€‰ï¼šEmbedding é…ç½®
EMBEDDING_API_URL=https://api.openai.com/v1
EMBEDDING_API_KEY=sk-your-openai-key
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# å¯é€‰ï¼šLangfuse å¯è§‚æµ‹æ€§
LANGFUSE_PUBLIC_KEY=pk-xxx
LANGFUSE_SECRET_KEY=sk-xxx
```

### 1.2 ä¸€é”®å¯åŠ¨

```bash
docker compose up -d --build
```

æœåŠ¡å¯åŠ¨åï¼š
- **API æœåŠ¡**: http://localhost:8000
- **Qdrant æ§åˆ¶å°**: http://localhost:6333/dashboard
- **Redis**: localhost:6379

### 1.3 API è°ƒç”¨ç¤ºä¾‹

#### æ–¹å¼ä¸€ï¼šSwagger UIï¼ˆæ¨èï¼‰

FastAPI è‡ªå¸¦äº¤äº’å¼ API æ–‡æ¡£ï¼Œæ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š

```
http://localhost:8000/docs
```

åœ¨ Swagger UI ä¸­å¯ä»¥ç›´æ¥ï¼š
- å¡«å†™ `problem_description`ï¼ˆéœ€æ±‚æè¿°ï¼‰
- ä¸Šä¼  `code_zip`ï¼ˆä»£ç å‹ç¼©åŒ…ï¼‰
- ç‚¹å‡» **Execute** æ‰§è¡Œåˆ†æ

![Swagger UI](docs/images/swagger-ui.png)

#### æ–¹å¼äºŒï¼šcURL å‘½ä»¤è¡Œ

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/

# ä»£ç åˆ†æï¼ˆä¸Šä¼  ZIP å‹ç¼©åŒ…ï¼‰
curl -X POST http://localhost:8000/api/review \
  -F "problem_description=å®ç°ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€åˆ—è¡¨æŸ¥è¯¢åŠŸèƒ½" \
  -F "code_zip=@your-project.zip"
```

### 1.4 è¿è¡Œç¤ºä¾‹

> **â±ï¸ åˆ†ææ—¶é•¿**ï¼šä¸éœ€æ±‚å¤æ‚åº¦æ­£ç›¸å…³ã€‚æœ¬ Demo è®¾ç½®ä»…åˆ†ææ ¸å¿ƒåŠŸèƒ½ç‚¹ï¼ˆçº¦ 3 ä¸ªï¼‰ï¼Œå®Œæ•´åˆ†æå¯è¯†åˆ« 9+ åŠŸèƒ½ç‚¹ã€‚

**æ ¸å¿ƒæµç¨‹**ï¼š
1. **ä»£ç è§£æ** â†’ Tree-sitter AST æå– + å‘é‡åŒ–ç´¢å¼•
2. **ç‰¹æ€§åˆ†æ** â†’ LLM å¹¶è¡Œåˆ†æå„åŠŸèƒ½ç‚¹å®ç°ä½ç½®
3. **æµ‹è¯•éªŒè¯** â†’ Docker æ²™ç®±æ‰§è¡Œ + ReAct è‡ªä¿®å¤å¾ªç¯ï¼ˆæœ€å¤š 3 æ¬¡é‡è¯•ï¼‰

**å¯è§‚æµ‹æ€§**ï¼šé€šè¿‡ [Langfuse](https://cloud.langfuse.com) è¿½è¸ª LLM è°ƒç”¨é“¾è·¯å’Œ Token æ¶ˆè€—ã€‚

![Langfuse è°ƒç”¨è¿½è¸ª](docs/images/langfuse-trace.png)

**è¿è¡Œæ—¥å¿—**ï¼ˆDockerï¼‰ï¼š
```bash
code-analyze-app     | INFO:     127.0.0.1:44824 - "GET / HTTP/1.1" 200 OK
code-analyze-qdrant  | 2025-12-30T13:30:01.339691Z  INFO actix_web::middleware::logger: 192.168.147.4 "PUT /collections/code_blocks/points?wait=true HTTP/1.1" 200 92 "-" "python-client/1.16.2 python/3.11.14" 0.015538
code-analyze-app     | INFO:     127.0.0.1:40110 - "GET / HTTP/1.1" 200 OK
code-analyze-app     | 13:29:43 | ============================================================
code-analyze-app     | 13:29:43 | ğŸš€ Starting code analysis...
code-analyze-app     | 13:29:43 | ============================================================
code-analyze-app     | 13:29:43 | ğŸ“¦ [1/5] Extracting ZIP file...
code-analyze-app     | 13:29:43 |    âœ“ Extracted 38 files (0.0s)
code-analyze-app     | 13:29:43 | ğŸ” [2/5] Parsing code structure...
code-analyze-app     | 13:29:43 |    âœ“ Found 65 definitions (0.1s)
code-analyze-app     | 13:29:43 | ğŸ§® [3/5] Generating embeddings...
code-analyze-app     | 13:29:49 | Embedded batch 1, total: 32/65
code-analyze-app     | 13:29:56 | Embedded batch 2, total: 64/65
code-analyze-app     | 13:30:00 | Embedded batch 3, total: 65/65
code-analyze-app     | 13:30:01 |    âœ“ Indexed 65 definitions (17.6s)
code-analyze-app     | 13:30:01 |    âœ“ Cached 65 definitions
code-analyze-app     | 13:30:01 | ğŸ¤– [4/5] Analyzing features with LLM...
code-analyze-app     | 13:30:01 | Langfuse tracing enabled
code-analyze-app     | 13:30:01 |       â†’ Extracting features from problem description...
code-analyze-app     | INFO:     127.0.0.1:38974 - "GET / HTTP/1.1" 200 OK
code-analyze-app     | 13:30:06 | [extract_features] LLM usage: 336 + 158 tokens
code-analyze-app     | 13:30:06 | Extracted 3 features: ['å®ç°åˆ›å»ºé¢‘é“åŠŸèƒ½', 'å®ç°åœ¨é¢‘é“ä¸­å‘é€æ¶ˆæ¯åŠŸèƒ½', 'å®ç°æŒ‰é™åºåˆ—å‡ºé¢‘é“æ¶ˆæ¯åŠŸèƒ½']
code-analyze-app     | 13:30:06 |       â†’ Found 3 features (5.3s)
code-analyze-app     | 13:30:06 |       â†’ Analyzing feature implementations (parallel)...
code-analyze-app     | 13:30:09 | Embedded batch 1, total: 1/1
code-analyze-app     | 13:30:09 | Embedded batch 1, total: 1/1
code-analyze-app     | 13:30:09 | Embedded batch 1, total: 1/1
code-analyze-app     | 13:30:14 | [analyze_feature:å®ç°åˆ›å»ºé¢‘é“åŠŸèƒ½] LLM usage: 7269 + 157 tokens
code-analyze-app     | 13:30:15 | [analyze_feature:å®ç°åœ¨é¢‘é“ä¸­å‘é€æ¶ˆæ¯åŠŸèƒ½] LLM usage: 7303 + 352 tokens
code-analyze-app     | 13:30:15 | [generate_execution_plan] LLM usage: 6767 + 305 tokens
code-analyze-app     | 13:30:16 | [analyze_feature:å®ç°æŒ‰é™åºåˆ—å‡ºé¢‘é“æ¶ˆæ¯åŠŸèƒ½] LLM usage: 7342 + 321 tokens
code-analyze-app     | 13:30:16 | Analyzed 3 features, 3 have locations
code-analyze-app     | 13:30:16 |       â†’ 3 features analyzed (10.0s)
code-analyze-app     | 13:30:16 | ğŸ§ª [5/5] Running functional verification...
code-analyze-app     | 13:31:20 | [generate_test_code] LLM usage: 2599 + 5424 tokens
code-analyze-app     | 13:31:20 |       â†’ Writing test file...
code-analyze-app     | 13:31:20 |       â†’ Creating test runner script...
code-analyze-app     | 13:31:20 |       â†’ Starting Docker container (node:18-alpine)...
code-analyze-app     | 13:31:20 |       â†’ Executing tests in container...
code-analyze-app     | 13:32:55 | Tests failed on attempt 1, using LLM to fix...
code-analyze-app     | 13:34:39 | [fix_test_code] LLM usage: 1296 + 6871 tokens
code-analyze-app     | 13:34:39 |       â†’ Writing test file...
code-analyze-app     | 13:34:39 |       â†’ Creating test runner script...
code-analyze-app     | 13:34:39 |       â†’ Starting Docker container (node:18-alpine)...
code-analyze-app     | 13:34:39 |       â†’ Executing tests in container...
code-analyze-app     | 13:35:34 | Tests failed on attempt 2, using LLM to fix...
code-analyze-app     | 13:36:49 | [fix_test_code] LLM usage: 1399 + 5291 tokens
code-analyze-app     | 13:36:49 |       â†’ Writing test file...
code-analyze-app     | 13:36:49 |       â†’ Creating test runner script...
code-analyze-app     | 13:36:49 |       â†’ Starting Docker container (node:18-alpine)...
code-analyze-app     | 13:36:49 |       â†’ Executing tests in container...
code-analyze-app     | 13:37:42 | Tests passed on attempt 3
code-analyze-app     | 13:37:42 |       â†’ Tests âœ… PASSED (446.2s)
code-analyze-app     | 13:37:42 |    âœ“ Analysis complete (461.5s)
code-analyze-app     | 13:37:42 | ============================================================
code-analyze-app     | 13:37:42 | âœ… Done! Total time: 479.2s
code-analyze-app     | 13:37:42 | ============================================================
```
**ç»“æœ**
```bash
{
  "success": true,
  "report": {
    "feature_analysis": [
      {
        "feature_description": "å®ç°åˆ›å»ºé¢‘é“åŠŸèƒ½",
        "implementation_location": [
          {
            "file": "src/modules/channel/channel.resolver.ts",
            "function": "createChannel",
            "lines": "13-17"
          },
          {
            "file": "src/modules/channel/channel.service.ts",
            "function": "create",
            "lines": "28-31"
          }
        ]
      },
      {
        "feature_description": "å®ç°å‘é€é¢‘é“æ¶ˆæ¯åŠŸèƒ½",
        "implementation_location": [
          {
            "file": "src/modules/message/message.resolver.ts",
            "function": "createMessage",
            "lines": "13-17"
          },
          {
            "file": "src/modules/message/message.service.ts",
            "function": "create",
            "lines": "29-40"
          }
        ]
      },
      {
        "feature_description": "æŒ‰æ—¶é—´å€’åºåˆ—å‡ºæŒ‡å®šé¢‘é“çš„æ¶ˆæ¯",
        "implementation_location": [
          {
            "file": "src/modules/message/message.service.ts",
            "function": "findAll",
            "lines": "49-76"
          }
        ]
      },
      {
        "feature_description": "å®ç°åˆ†é¡µåˆ—å‡ºé¢‘é“æ¶ˆæ¯çš„æŸ¥è¯¢èƒ½åŠ›ï¼ŒåŒ…æ‹¬è§£æåˆ†é¡µå‚æ•°å¹¶æŒ‰æ¡ä»¶æŸ¥è¯¢æ¶ˆæ¯åˆ—è¡¨ã€‚",
        "implementation_location": [
          {
            "file": "src/modules/message/message.resolver.ts",
            "function": "findAll",
            "lines": "20-22"
          },
          {
            "file": "src/modules/message/message.service.ts",
            "function": "findAll",
            "lines": "49-76"
          },
          {
            "file": "src/modules/message/dto/messages.args.ts",
            "function": "MessagesArgs",
            "lines": "5-8"
          },
          {
            "file": "src/common/dto/list.args.ts",
            "function": "ListArgs",
            "lines": "5-29"
          }
        ]
      }
    ],
    "execution_plan_suggestion": "1. å®‰è£…ä¾èµ–ï¼šnpm install  \n2. é…ç½®ç¯å¢ƒï¼šPORTã€NODE_ENVã€DATABASE_PATH ç­‰  \n3. å¯åŠ¨æœåŠ¡ï¼šnpm run start:devï¼Œè®¿é—® /graphql",
    "functional_verification": {
      "generated_test_code": "const request = require('supertest');\nconst assert = require('assert');\n\ndescribe('Channel and Message GraphQL API', () => {\n  const client = request('http://localhost:3000');\n  let channelId;\n  const createdMessages = [];\n  let orderedMessages = [];\n\n  it('should create a channel', async () => {\n    const channelName = `Test Channel ${Date.now()}`;\n    const res = await client\n      .post('/graphql')\n      .send({\n        query: `\n          mutation ($input: CreateChannelInput!) {\n            createChannel(createChannelInput: $input) {\n              id\n              name\n              createdAt\n              updatedAt\n            }\n          }\n        `,\n        variables: {\n          input: {\n            name: channelName,\n          },\n        },\n      });\n\n    assert.strictEqual(res.status, 200);\n    assert.ok(!res.body.errors, res.body.errors && JSON.stringify(res.body.errors));\n    const channel = res.body.data.createChannel;\n    assert.ok(channel);\n    assert.ok(channel.id);\n    assert.strictEqual(channel.name, channelName);\n    channelId = channel.id;\n  });\n\n  it('should create messages for the channel', async () => {\n    assert.ok(channelId, 'Channel ID should be defined before creating messages');\n    const baseTimestamp = Date.now();\n    const messagesPayload = [\n      {\n        title: `First Message ${baseTimestamp}`,\n        content: 'Content for first message',\n      },\n      {\n        title: `Second Message ${baseTimestamp + 1}`,\n        content: 'Content for second message',\n      },\n      {\n        title: `Third Message ${baseTimestamp + 2}`,\n        content: 'Content for third message',\n      },\n    ];\n\n    for (const payload of messagesPayload) {\n      const res = await client\n        .post('/graphql')\n        .send({\n          query: `\n            mutation ($input: CreateMessageInput!) {\n              createMessage(createMessageInput: $input) {\n                id\n                title\n                content\n                channel {\n                  id\n                  name\n                }\n                createdAt\n                updatedAt\n              }\n            }\n          `,\n          variables: {\n            input: {\n              title: payload.title,\n              content: payload.content,\n              channelId,\n            },\n          },\n        });\n\n      assert.strictEqual(res.status, 200);\n      assert.ok(!res.body.errors, res.body.errors && JSON.stringify(res.body.errors));\n      const message = res.body.data.createMessage;\n      assert.ok(message);\n      assert.ok(message.id);\n      assert.strictEqual(message.channel.id, channelId);\n      assert.strictEqual(message.title, payload.title);\n      assert.strictEqual(message.content, payload.content);\n      createdMessages.push(message);\n    }\n\n    assert.strictEqual(createdMessages.length, messagesPayload.length);\n  });\n\n  it('should list messages in descending order by createdAt', async () => {\n    const res = await client\n      .post('/graphql')\n      .send({\n        query: `\n          query ($channelId: Int!, $sortBy: String) {\n            messages(channelId: $channelId, sortBy: $sortBy) {\n              id\n              title\n              content\n              channel {\n                id\n                name\n              }\n              createdAt\n              updatedAt\n            }\n          }\n        `,\n        variables: {\n          channelId,\n          sortBy: 'createdAt:DESC',\n        },\n      });\n\n    assert.strictEqual(res.status, 200);\n    assert.ok(!res.body.errors, res.body.errors && JSON.stringify(res.body.errors));\n    const messages = res.body.data.messages;\n    assert.ok(Array.isArray(messages));\n    assert.strictEqual(messages.length, createdMessages.length);\n    messages.forEach((message) => {\n      assert.strictEqual(message.channel.id, channelId);\n    });\n\n    const createdAtTimes = messages.map((msg) => new Date(msg.createdAt).getTime());\n    for (let i = 1; i < createdAtTimes.length; i += 1) {\n      assert.ok(\n        createdAtTimes[i] <= createdAtTimes[i - 1],\n        'Messages should be ordered by createdAt descending'\n      );\n    }\n\n    orderedMessages = messages;\n  });\n\n  it('should paginate messages with skip and take parameters', async () => {\n    assert.ok(orderedMessages.length >= 2, 'Need at least two messages to test pagination');\n    const res = await client\n      .post('/graphql')\n      .send({\n        query: `\n          query ($channelId: Int!, $skip: Int!, $take: Int!, $sortBy: String) {\n            messages(channelId: $channelId, skip: $skip, take: $take, sortBy: $sortBy) {\n              id\n              title\n              content\n              channel {\n                id\n                name\n              }\n              createdAt\n              updatedAt\n            }\n          }\n        `,\n        variables: {\n          channelId,\n          skip: 1,\n          take: 1,\n          sortBy: 'createdAt:DESC',\n        },\n      });\n\n    assert.strictEqual(res.status, 200);\n    assert.ok(!res.body.errors, res.body.errors && JSON.stringify(res.body.errors));\n    const pagedMessages = res.body.data.messages;\n    assert.ok(Array.isArray(pagedMessages));\n    assert.strictEqual(pagedMessages.length, 1);\n    const expectedMessage = orderedMessages[1];\n    const pagedMessage = pagedMessages[0];\n    assert.strictEqual(pagedMessage.id, expectedMessage.id);\n    assert.strictEqual(pagedMessage.title, expectedMessage.title);\n    assert.strictEqual(pagedMessage.content, expectedMessage.content);\n    assert.strictEqual(pagedMessage.channel.id, channelId);\n  });\n});",
      "execution_result": {
        "tests_passed": true,
        "log": "  Channel and Message GraphQL API\n    âœ” should create a channel (41ms)\n    âœ” should create messages for the channel\n    âœ” should list messages in descending order by createdAt\n    âœ” should paginate messages with skip and take parameters\n\n\n  4 passing (89ms)\n\n"
      }
    }
  }
}
```


### 1.5 å¸¸ç”¨è¿ç»´å‘½ä»¤

```bash
docker compose logs -f app      # æŸ¥çœ‹æ—¥å¿—
docker compose down             # åœæ­¢æœåŠ¡
docker compose down -v          # åœæ­¢å¹¶æ¸…é™¤æ•°æ®
```

---

## ğŸ”¬ Part 2: æŠ€æœ¯æ¶æ„ä¸å®ç°

### 2.1 ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API Layer (FastAPI)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Code Parser â”‚â”€â”€â”€â”€â”‚  Embedding  â”‚â”€â”€â”€â”€â”‚  Vector Store       â”‚  â”‚
â”‚  â”‚ (Tree-sitter)â”‚    â”‚  (OpenAI)   â”‚    â”‚  (Qdrant)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                        â”‚                â”‚
â”‚         â–¼                                        â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Feature Analyzer (LLM + RAG)                  â”‚  â”‚
â”‚  â”‚  â€¢ ç‰¹æ€§æå– â†’ è¯­ä¹‰æ£€ç´¢ â†’ å¹¶è¡Œåˆ†æ â†’ ç»“æœèšåˆ              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                         â”‚
â”‚         â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Docker Executor (Isolated Sandbox)                â”‚  â”‚
â”‚  â”‚  â€¢ æµ‹è¯•ç”Ÿæˆ â†’ Docker æ‰§è¡Œ â†’ ReAct ä¿®å¤å¾ªç¯                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒæŠ€æœ¯è¯¦è§£

#### ğŸŒ² Tree-sitter å¤šè¯­è¨€ä»£ç è§£æ + é€’å½’åˆ†å—

**é—®é¢˜**ï¼š
1. æ­£åˆ™è¡¨è¾¾å¼éš¾ä»¥å‡†ç¡®è§£æå¤æ‚ä»£ç ç»“æ„ï¼ˆåµŒå¥—å‡½æ•°ã€è£…é¥°å™¨ã€æ³›å‹ç­‰ï¼‰
2. å¤§å‹ç±»/å‡½æ•°ï¼ˆ>1500 å­—ç¬¦ï¼‰è¶…å‡º Embedding æœ€ä½³é•¿åº¦ï¼Œå½±å“è¯­ä¹‰æ£€ç´¢è´¨é‡

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ Tree-sitter æ„å»º AST æŠ½è±¡è¯­æ³•æ ‘ï¼Œç²¾å‡†æå–ä»£ç å®šä¹‰
- **è¶…é•¿ä»£ç é€’å½’åˆ†å—**ï¼šå½“ä»£ç å— > 1500 å­—ç¬¦æ—¶ï¼Œé€’å½’æ‹†åˆ†ä¸ºå­èŠ‚ç‚¹

```python
# app/services/code_parser.py
class CodeParser:
    MAX_BLOCK_CHARS = 1500  # è¶…è¿‡æ­¤é•¿åº¦é€’å½’æ‹†åˆ†
    
    def _extract_definitions(self, node, ...) -> List[CodeDefinition]:
        content = self._get_node_text(node)
        
        # é€’å½’åˆ†å—ï¼šè¶…é•¿ä»£ç æ‹†åˆ†ä¸ºå­èŠ‚ç‚¹
        if len(content) > self.MAX_BLOCK_CHARS and node.children:
            for child in node.children:
                if self._is_definition(child):
                    definitions.extend(self._extract_definitions(child))
        else:
            definitions.append(CodeDefinition(content=content, ...))
        
        return definitions
```

**æŠ€æœ¯ä¼˜åŠ¿**ï¼š
- ä¿æŒä»£ç è¯­ä¹‰å®Œæ•´æ€§ï¼ˆæŒ‰ AST èŠ‚ç‚¹è¾¹ç•Œæ‹†åˆ†ï¼Œéå›ºå®šé•¿åº¦åˆ‡å‰²ï¼‰
- æå‡ Embedding è´¨é‡ï¼ˆæ¯ä¸ªå— â‰¤1500 å­—ç¬¦ï¼Œæœ€ä½³è¯­ä¹‰å¯†åº¦ï¼‰
- æ”¯æŒåµŒå¥—ç»“æ„ï¼ˆç±»ä¸­çš„æ–¹æ³•ã€æ¨¡å—ä¸­çš„å‡½æ•°ï¼‰

**æ”¯æŒè¯­è¨€**ï¼šTypeScript, JavaScript, Python, Java, Go, Rust, Ruby, PHP, C#, C/C++

---

#### ğŸ” RAG è¯­ä¹‰æ£€ç´¢

**é—®é¢˜**ï¼šå¤§å‹ä»£ç åº“æ— æ³•å…¨éƒ¨æ”¾å…¥ LLM ä¸Šä¸‹æ–‡ï¼Œéœ€è¦ç²¾å‡†å®šä½ç›¸å…³ä»£ç ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä»£ç åˆ†å— â†’ Embedding å‘é‡åŒ– â†’ Qdrant å­˜å‚¨
2. éœ€æ±‚ç‰¹æ€§ â†’ è¯­ä¹‰æ£€ç´¢ â†’ Top-K ç›¸å…³ä»£ç ç‰‡æ®µ

```python
# app/services/feature_analyzer.py
async def _search_relevant_code(self, feature: str) -> List[CodeDefinition]:
    """è¯­ä¹‰æ£€ç´¢ä¸ç‰¹æ€§ç›¸å…³çš„ä»£ç ç‰‡æ®µ"""
    results = await self.qdrant_client.search(
        collection_name="code_blocks",
        query_vector=await self._embed(feature),
        limit=10,  # Top-10 æœ€ç›¸å…³
    )
    return [self._to_definition(r) for r in results]
```

---

#### âš¡ å¼‚æ­¥å¹¶è¡Œå¤„ç†

**é—®é¢˜**ï¼šå¤šä¸ªç‰¹æ€§ä¸²è¡Œåˆ†æè€—æ—¶è¿‡é•¿ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ `asyncio.gather` å¹¶è¡Œåˆ†æï¼ŒåŒæ—¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ã€‚

```python
# app/services/feature_analyzer.py
async def generate_report(self, features: List[str]) -> AnalysisReport:
    """å¹¶è¡Œåˆ†ææ‰€æœ‰ç‰¹æ€§ + ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
    feature_analyses, execution_plan = await asyncio.gather(
        self.analyze_all_features(features),      # å¹¶è¡Œåˆ†æ
        self.llm_client.generate_execution_plan() # åŒæ—¶ç”Ÿæˆ
    )
    return AnalysisReport(feature_analyses, execution_plan)
```

**æ€§èƒ½æå‡**ï¼š3 ä¸ªç‰¹æ€§åˆ†æä» ~30s é™è‡³ ~12sï¼ˆçº¦ 2.5x åŠ é€Ÿï¼‰

---

#### ğŸ”„ ReAct è‡ªä¿®å¤å¾ªç¯

**é—®é¢˜**ï¼šLLM ç”Ÿæˆçš„æµ‹è¯•ä»£ç å¯èƒ½æœ‰è¯­æ³•é”™è¯¯æˆ–é€»è¾‘é—®é¢˜ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šå®ç° ReAct (Reasoning + Acting) å¾ªç¯ï¼Œå¤±è´¥åè‡ªåŠ¨è¯Šæ–­å¹¶ä¿®å¤ã€‚

```python
# app/services/feature_analyzer.py
MAX_RETRY = 2

for attempt in range(MAX_RETRY + 1):
    result = await docker_executor.execute_tests(test_code)
    
    if result.tests_passed:
        break  # æˆåŠŸï¼Œç»“æŸå¾ªç¯
    
    if attempt < MAX_RETRY:
        # LLM åˆ†æé”™è¯¯æ—¥å¿—ï¼Œç”Ÿæˆä¿®å¤åçš„ä»£ç 
        test_code = await llm_client.fix_test_code(
            original_code=test_code,
            error_log=result.log,
        )
```

**æˆåŠŸç‡æå‡**ï¼šé¦–æ¬¡é€šè¿‡ç‡ ~60% â†’ ä¸‰æ¬¡å¾ªç¯å ~90%

---

#### ğŸ³ Docker-in-Docker æ²™ç®±æ‰§è¡Œ

**é—®é¢˜**ï¼šéœ€è¦å®‰å…¨æ‰§è¡Œç”¨æˆ·ä¸Šä¼ çš„ä»£ç ï¼Œä¸èƒ½æ±¡æŸ“ä¸»æœºç¯å¢ƒã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æŒ‚è½½ `docker.sock` å®ç° Docker-in-Docker
- æ¯æ¬¡æµ‹è¯•ä½¿ç”¨ç‹¬ç«‹å®¹å™¨ï¼Œæ‰§è¡Œå®Œæ¯•è‡ªåŠ¨é”€æ¯
- æ”¯æŒ Node.js å’Œ Python é¡¹ç›®

```python
# app/services/docker_executor.py
docker_cmd = [
    "docker", "run", "--rm",
    "-v", f"{volume_mount}",
    "-w", work_dir,
    "node:18-alpine",
    "/bin/sh", "-c", "npm install && bash run_tests.sh"
]
```

---

#### ï¿½ æ™ºèƒ½ç¼“å­˜ç­–ç•¥

**é—®é¢˜**ï¼šç›¸åŒä»£ç é‡å¤åˆ†ææµªè´¹èµ„æºã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šåŸºäºå†…å®¹å“ˆå¸Œçš„ Redis ç¼“å­˜ã€‚

```python
# app/api/endpoints/review.py
cache_key = hashlib.md5(zip_content).hexdigest()
cached = await redis.get(cache_key)
if cached:
    return cached  # ç§’çº§å“åº”

# åˆ†æåç¼“å­˜
await redis.set(cache_key, result, ex=3600)
```

---

### 2.3 é¡¹ç›®ç»“æ„

```
code-analyze/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/endpoints/      # API è·¯ç”±
â”‚   â”‚   â””â”€â”€ review.py       # ä»£ç åˆ†æå…¥å£
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ llm_client.py   # LLM å®¢æˆ·ç«¯ (OpenAI å…¼å®¹)
â”‚   â”‚   â”œâ”€â”€ embeddings.py   # å‘é‡åµŒå…¥
â”‚   â”‚   â””â”€â”€ prompts.py      # Prompt æ¨¡æ¿
â”‚   â”œâ”€â”€ services/           # ä¸šåŠ¡æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ code_parser.py     # Tree-sitter è§£æ
â”‚   â”‚   â”œâ”€â”€ feature_analyzer.py # ç‰¹æ€§åˆ†æ + RAG
â”‚   â”‚   â”œâ”€â”€ test_generator.py   # æµ‹è¯•ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ docker_executor.py  # Docker æ‰§è¡Œ
â”‚   â”‚   â””â”€â”€ templates.py        # Shell è„šæœ¬æ¨¡æ¿
â”‚   â””â”€â”€ models/             # Pydantic æ•°æ®æ¨¡å‹
â”œâ”€â”€ docker-compose.yml      # å®¹å™¨ç¼–æ’
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ Makefile                # å¼€å‘å‘½ä»¤
```

---

### 2.4 å¯è§‚æµ‹æ€§ (Langfuse)

é›†æˆ Langfuse è¿½è¸ª LLM è°ƒç”¨ï¼Œæ”¯æŒï¼š
- Token ç”¨é‡ç»Ÿè®¡
- å“åº”å»¶è¿Ÿç›‘æ§
- Prompt ç‰ˆæœ¬ç®¡ç†
- è°ƒç”¨é“¾è·¯è¿½è¸ª

```python
# æ¯ä¸ª LLM è°ƒç”¨è‡ªåŠ¨ä¸ŠæŠ¥
[extract_features] LLM usage: 336 + 996 tokens
[analyze_feature:xxx] LLM usage: 7267 + 1294 tokens
[generate_test_code] LLM usage: 2794 + 3901 tokens
```

---

## ğŸ› ï¸ æœ¬åœ°å¼€å‘

```bash
# å®‰è£… uv åŒ…ç®¡ç†å™¨
pip install uv

# å®‰è£…ä¾èµ–
uv sync

# å¯åŠ¨ Redis + Qdrant
docker compose up redis qdrant -d

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
make dev
```

---

## ğŸ“‹ ç¯å¢ƒå˜é‡å‚è€ƒ

| å˜é‡ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|:----:|--------|------|
| `LLM_API_URL` | âœ… | `https://openrouter.ai/api` | LLM API åœ°å€ |
| `LLM_API_KEY` | âœ… | - | API å¯†é’¥ |
| `LLM_MODEL` | âœ… | `openai/gpt-5-codex` | æ¨¡å‹åç§° |
| `EMBEDDING_API_URL` | âŒ | `${LLM_API_URL}` | Embedding API åœ°å€ |
| `EMBEDDING_DIMENSION` | âŒ | `1024` | å‘é‡ç»´åº¦ |
| `LANGFUSE_PUBLIC_KEY` | âŒ | - | Langfuse å…¬é’¥ |
| `LANGFUSE_SECRET_KEY` | âŒ | - | Langfuse ç§é’¥ |

---
